{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "MODEL_PATH = \"/home/zhanghaoyu/models/Llama-3.1-8B-Instruct/\"\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "DTYPE = torch.float16\n",
    "torch.set_default_dtype(DTYPE)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "method = \"hf\"\n",
    "token_budget = 1024\n",
    "topp = None\n",
    "\n",
    "if method == \"quest\":\n",
    "  from quest import LlamaForCausalLM\n",
    "  model = LlamaForCausalLM.from_pretrained(MODEL_PATH, device_map=DEVICE, torch_dtype=DTYPE, output_attentions=True)\n",
    "\n",
    "  # Init Quest Controller\n",
    "  model.quest_init(page_size=16, max_seq_len=8192, token_budget=token_budget, topp=topp)\n",
    "else:\n",
    "  from transformers import LlamaForCausalLM\n",
    "  model = LlamaForCausalLM.from_pretrained(MODEL_PATH, device_map=DEVICE, torch_dtype=DTYPE, output_attentions=True)\n",
    "  \n",
    "def plot_attention_heatmap(attentions, token_idx, layer_idx, head_idx, tokens):\n",
    "  attention = attentions[token_idx][layer_idx][0, head_idx].detach().cpu().numpy()  # [seq_len, seq_len]\n",
    "  current_tokens = tokens[:attention.shape[0]]  # sequence_length tokens\n",
    "  plt.figure(figsize=(10, 8))\n",
    "  sns.heatmap(attention, xticklabels=current_tokens, yticklabels=current_tokens, cmap=\"viridis\")\n",
    "  plt.title(f\"Attention Heatmap (Layer {layer_idx}, Head {head_idx}) of Token {token_idx}\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"In an animal kingdom, the lion is the king. One day, the lion announces a competition to choose the most hardworking animal. The turtle, rabbit, monkey, zebra, and giraffe all decide to participate. After a day of observation, the lion notices that all the animals are working hard, except for the rabbit, who is sleeping. So why does the lion choose the rabbit as the most hardworking animal?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "print(f\"Input Sequence Length: {inputs.input_ids.shape[1]}\")\n",
    "\n",
    "outputs = model.generate(\n",
    "  **inputs,\n",
    "  max_new_tokens=8192,\n",
    "  output_attentions=True,\n",
    "  return_dict_in_generate=True\n",
    ")\n",
    "\n",
    "generated_ids = outputs.sequences\n",
    "attentions = outputs.attentions # (output_tokens, batch_size, num_heads, sequence_length, sequence_length)\n",
    "generated_tokens = tokenizer.convert_ids_to_tokens(generated_ids[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
